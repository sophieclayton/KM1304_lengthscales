{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import acf, ccf\n",
    "from statsmodels.tsa.tsatools import detrend\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy.signal as signal\n",
    "import time as tm\n",
    "import gsw as sw\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import chi2\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from netCDF4 import Dataset as NetCDFFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_KM(sds):\n",
    "    lon_tmp = sds[(sds['cruise']=='KiloMoana_1')]['lon']\n",
    "    lon_tmp = lon_tmp//100 + (lon_tmp - lon_tmp//100*100)/60\n",
    "    lat_tmp = sds[(sds['cruise']=='KiloMoana_1')]['lat']\n",
    "    lat_tmp = lat_tmp//100 + (lat_tmp - lat_tmp//100*100)/60\n",
    "    \n",
    "    sds.loc[sds['cruise']=='KiloMoana_1','lon'] = -lon_tmp\n",
    "    sds.loc[sds['cruise']=='KiloMoana_1','lat'] = lat_tmp\n",
    "    \n",
    "    lon_tmp2 = sds[(sds['cruise']=='SCOPE_2')]['lon']\n",
    "    lon_tmp2 = lon_tmp2//100 + (lon_tmp2 - lon_tmp2//100*100)/60\n",
    "    lat_tmp2 = sds[(sds['cruise']=='SCOPE_2')]['lat']\n",
    "    lat_tmp2 = lat_tmp2//100 + (lat_tmp2 - lat_tmp2//100*100)/60\n",
    "    \n",
    "    sds.loc[sds['cruise']=='SCOPE_2','lon'] = -lon_tmp2\n",
    "    sds.loc[sds['cruise']=='SCOPE_2','lat'] = lat_tmp2\n",
    "    \n",
    "    return sds\n",
    "\n",
    "def checklon(data):\n",
    "    cxx = (data['lon']).values # longitude\n",
    "\n",
    "    # convert all longitude to longitude east\n",
    "    cxx[cxx<0]= 360+cxx[cxx<0];\n",
    "    data['lon_e'] = cxx\n",
    "    cxbew = cxx\n",
    "    cxbew[cxbew>180] = cxbew[cxbew>180]-360   \n",
    "    data['lon'] = cxbew\n",
    "    return data\n",
    "\n",
    "def distance(data):\n",
    "    cruise = pd.unique(data['cruise'])\n",
    "    distances = pd.DataFrame()    \n",
    "    for c in cruise:\n",
    "        temp = pd.DataFrame()\n",
    "        temp = data.loc[(data['cruise']==c), ['cruise','file_time','lon','lat']]\n",
    "        \n",
    "        # calculate distance in km between points\n",
    "        temp['dx'] = np.insert(sw.distance(temp['lon'].values, temp['lat'].values, 0),0,0)/1000\n",
    "        temp['x'] = np.cumsum(temp['dx'])\n",
    "        \n",
    "        if c == cruise[0]:\n",
    "            distances = distances.append(temp)\n",
    "        else:\n",
    "            distances = pd.concat([distances, temp], axis=0)\n",
    "        del temp\n",
    "    data = pd.merge(left = data, right = distances, how='left', left_on=['cruise','file_time','lat','lon'], right_on=['cruise','file_time','lat','lon'])\n",
    "    #return distances\n",
    "\n",
    "    return data  \n",
    "\n",
    "def tracks(data):\n",
    "    seg = []\n",
    "    start = 0\n",
    "    n = 1\n",
    "    for i in range(len(data)):\n",
    "        if ((data['dx'][i] > 20) | (data['dx'][i] < 0.01)):\n",
    "            seg.append([data['cruise'][i], start, i-1, sum(data['dx'][start:i-1])])# - data['x'][start])])\n",
    "                                                         \n",
    "            n += 1\n",
    "            start = i+1\n",
    "    \n",
    "    segments = pd.DataFrame(seg, columns = ['cruise', 'start', 'end', 'length']) \n",
    "    segments = segments.loc[(segments['length'] >= 200)]\n",
    "    segments = segments.loc[(segments['end'] > 0)]\n",
    "    segments['number'] = range(1, len(segments)+1)\n",
    "    segments = segments.set_index(['number'])\n",
    "    return segments\n",
    "\n",
    "\n",
    "def interpdata(track, aa, bb, var):\n",
    "    # we went to create a new dataframe which has the interpolated data for each track for all variables, \n",
    "    # and a position.\n",
    "    intdata = pd.DataFrame()\n",
    "    # set the interpolation distance \n",
    "    n = 1 # 1km \n",
    "    begin = np.floor(track['x'][:1])\n",
    "    intdata['x'] = np.arange(aa, bb, n)\n",
    " \n",
    "    for v in var:\n",
    "        intdata[v] = np.interp(intdata['x'].values,track['x'].values,track[v].values)\n",
    "          \n",
    "    return intdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'cruise', u'file_time', u'opp_evt_ratio', u'flow_rate',\n",
      "       u'beads', u'picoeuk', u'prochloro', u'synecho', u'unknown', u'cocco',\n",
      "       u'ts', u'file_duration', u'pico', u'Unnamed: 0.1', u'tot_chl',\n",
      "       u'file_time_r', u'Unnamed: 0.1', u'file_duration_r', u'lat', u'lon',\n",
      "       u'conductivity', u'salinity', u'ocean_tmp', u'par', u'bulk_red',\n",
      "       u'stream_pressure', u'flow_rate_r', u'event_rate', u'avg_chl',\n",
      "       u'avg_pe', u'avg_fsc', u'density', u'lon_e', u'dx', u'x', u'sds_time',\n",
      "       u'file_time_r.1', u'opp.evt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "filePath = '/Users/archie/Google Drive/seaflow_data/KM1_abun_sds_opp.csv'\n",
    "data = pd.read_csv(filePath, sep=',')\n",
    "\n",
    "filePath = r'/Users/archie/Google Drive/seaflow_data/sds_depth.csv'\n",
    "depth = pd.read_csv(filePath)\n",
    "\n",
    "filePath = r'/Users/archie/Google Drive/seaflow_data/sds_dist2coast.csv'\n",
    "dcoast = pd.read_csv(filePath)\n",
    "\n",
    "filePath = '/Users/archie/Google Drive/seaflow_data/KM1_chl.csv'\n",
    "chl = pd.read_csv(filePath, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/archie/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# add density \n",
    "data['density'] = sw.rho(data['salinity'].values,data['ocean_tmp'].values,0)\n",
    "data = checklon(data)\n",
    "\n",
    "# only keep KM1304 data\n",
    "data = data[(data['cruise']=='KiloMoana_1')]\n",
    "               \n",
    "# sort the dataframe so that it is in date/time order\n",
    "data = pd.merge(data, depth, on=['cruise','file_time'], how='inner')\n",
    "data = pd.merge(data, dcoast, on=['cruise','file_time'], how='inner')\n",
    "data = pd.merge(data, chl, on=['cruise','file_time'], how='inner')\n",
    "data = data.sort_values(by = ['cruise', 'file_time'],ascending=[1, 1])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# now we have a dataframe with the total alongtrack distance for each cruise, \n",
    "# and the distance between points for each file.\n",
    "\n",
    "clean = data[['cruise', 'file_time', 'lon', 'lon_e', 'lat', 'depth', 'dcoast', 'salinity', 'ocean_tmp', 'density', 'pico', 'synecho', 'picoeuk', 'chl']]\n",
    "clean['tot_chl'] = data['tot_chl']#/(data['file_duration']*data['opp.evt']*data['flow_rate'])\n",
    "clean = clean.sort_values(by = ['cruise', 'file_time'],ascending=[1, 1])\n",
    "clean = distance(clean)\n",
    "\n",
    "segments = tracks(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# identify location of fronts along the tracks\n",
    "# look at what Oliver did in model paper (Levy et al, 2014?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
